{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Bingjing-Dong/CSC448-AI/blob/main/Assignment%203.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature 째C</th>\n",
       "      <th>Mols KCL</th>\n",
       "      <th>Size nm^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>647</td>\n",
       "      <td>6.244743e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>694</td>\n",
       "      <td>5.779610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>975</td>\n",
       "      <td>6.196847e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>916</td>\n",
       "      <td>1.460449e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>18</td>\n",
       "      <td>4.325726e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>545</td>\n",
       "      <td>637</td>\n",
       "      <td>7.124634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>660</td>\n",
       "      <td>519</td>\n",
       "      <td>7.006960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>869</td>\n",
       "      <td>2.718260e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>461</td>\n",
       "      <td>8.919803e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294</td>\n",
       "      <td>776</td>\n",
       "      <td>4.770210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>991</td>\n",
       "      <td>117</td>\n",
       "      <td>2.441771e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>307</td>\n",
       "      <td>781</td>\n",
       "      <td>5.006455e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>206</td>\n",
       "      <td>70</td>\n",
       "      <td>3.145200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>437</td>\n",
       "      <td>599</td>\n",
       "      <td>5.390215e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>9.185271e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature 째C  Mols KCL     Size nm^3\n",
       "0              469       647  6.244743e+05\n",
       "1              403       694  5.779610e+05\n",
       "2              302       975  6.196847e+05\n",
       "3              779       916  1.460449e+06\n",
       "4              901        18  4.325726e+04\n",
       "5              545       637  7.124634e+05\n",
       "6              660       519  7.006960e+05\n",
       "7              143       869  2.718260e+05\n",
       "8               89       461  8.919803e+04\n",
       "9              294       776  4.770210e+05\n",
       "10             991       117  2.441771e+05\n",
       "11             307       781  5.006455e+05\n",
       "12             206        70  3.145200e+04\n",
       "13             437       599  5.390215e+05\n",
       "14             566        75  9.185271e+04"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "# Output the first 15 rows of the data\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature 째C  1000 non-null   int64  \n",
      " 1   Mols KCL        1000 non-null   int64  \n",
      " 2   Size nm^3       1000 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "X = dataset[['Temperature 째C','Mols KCL']]\n",
    "y = dataset['Size nm^3']\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [639732.83190002]\n",
      "Score: 0.858202107053349\n",
      "Coefficent: [ 877.26717297 1026.45679272]\n",
      "Intercept: -414714.18810411997\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "sample = np.array([[294, 776]])\n",
    "print(\"Prediction: \" + str(reg.predict(sample)))\n",
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "print(\"Score: \" + str(reg.score(X_test,y_test)))\n",
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "print(\"Coefficent: \" + str(reg.coef_))\n",
    "print(\"Intercept: \" + str(reg.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score function return the coefficient of determination of the prediction. Our score is 0.8582 here, which means the model has 86.161% accuracy of predicting the slime size given the temperature and mols.\n",
    "\n",
    "The equation of $h(x) = 877.26717x_1 + 1026.45679x_2 - 414714.1881$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Score: [0.83918826 0.87051239 0.85871066 0.87202623 0.84364641]\n",
      "0.85682 accuracy with a standard deviation of 0.01347\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "scores = cross_val_score(reg, X, y, cv=5)\n",
    "# Report on their finding and their significance\n",
    "print(\"Cross-validation Score: \" + str(scores))\n",
    "print(\"%0.5f accuracy with a standard deviation of %0.5f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to use cross-validation is to call the cross_val_score helper function on the estimator and the dataset.\n",
    "\n",
    "The accuracy of fitting the model and computing the score 5 consecutive times (with different splits each time) is between 0.83912 and 0.87203. The mean accuracy is 0.85682 which is closed to the test data score above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n",
      "coefficent: [ 0.00000000e+00  1.20000000e+01 -1.39313366e-07 -3.57011649e-11\n",
      "  2.00000000e+00  2.85714287e-02]\n",
      "intercept: 1.6176840290427208e-05\n"
     ]
    }
   ],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly.fit_transform(X), y, test_size=0.1)\n",
    "poly_reg = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Score: \" + str(poly_reg.score(X_test,y_test)))\n",
    "print(\"coefficent: \" + str(poly_reg.coef_))\n",
    "print(\"intercept: \" + str(poly_reg.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we use PolynomialFeatures library with data, the score became 1, which means the train model using polynomial regression has 100% accurate.\n",
    "\n",
    "The equation of $h(x) = 0.00002 + 0.12x_1 + 2x_1x_2 + 0.02857x_2^2$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
